{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69cd4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "import torch\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc717ce7-9812-496e-bdd6-d0dfbf2ee804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the device to load the model onto\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU\")\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4574e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks support token-wise streaming\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac14273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the model path is correct for your system!\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"Mistral-7B-Instruct-v0.1.gguf/mistral-7b-instruct-v0.1.Q5_K_M.gguf\",\n",
    "    temperature=0.75,\n",
    "    max_tokens=2000,\n",
    "    top_p=1,\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True,  # Verbose is required to pass to the callback manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b3816",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How has this trial helped?\"\n",
    "context = \"R DE was established as LHC165 600 g biweekly in combination with PDR001 400 mg Q4W. In single agent arm , no DLT was observed . In combination arm , one DLT of pancreatitis was reported . Comparable exposures of LHC165 were observed at same dose levels in single agent and combination arms . There was no impact on PK of LHC165 when given in combination with PDR001. The safety profile of LHC165 was well characterized in all treatment groups evaluated in this study . No major differences were observed between LHC165 as single agent vs . LHC165 + PDR001 combination . Overall , the safety profile of the doses explored was generally manageable .\"\n",
    "answer = \"This trial helped learn about the safety of different doses of LHC165 given alone or with PDR001 in participants with advanced cancers . The researchers concluded that 600 g LHC165 was the highest dose that was safe for participants to receive alone or with 400 mg PDR001. Because enrollment ended early and there were too few participants , the researchers could not make any conclusions about the effects of LHC165 given alone or with PDR001 on shrinking cancer . The sponsor has no plans for other trials of LHC165 in people with advanced cancers .\"\n",
    "# define prompt format to llm\n",
    "template = \"\"\"\n",
    "[INST] \n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "****************************************************************\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "****************************************************************\n",
    "\n",
    "INSTRUCTIONS:\n",
    "Answer the users QUESTION using the CONTEXT text above.\n",
    "Keep your answer ground in the facts of the CONTEXT and using plain language.\n",
    "[/INST]\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=context, question=question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(prompt.format(context=context, question=question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160fcaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Placeholder function to generate an LLM answer\n",
    "def generate_llm_answer(context, question):\n",
    "    result = llm.invoke(prompt.format(context=context, question=question))\n",
    "    return result\n",
    "\n",
    "def create_llm_answers(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Iterate over each object in the JSON array and add the 'llm_answer'\n",
    "    for item in data:\n",
    "        print(f'Current trial accessed: {item.get('trial_name', '')}')\n",
    "        context = item.get('context', '')\n",
    "        question = item.get('question', '')\n",
    "        llm_answer = generate_llm_answer(context, question)\n",
    "        item['llm_answer'] = llm_answer\n",
    "\n",
    "    # Save the updated JSON data to a new file\n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "    print(f\"Updated JSON data has been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7682240",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    \"How_has_this_trial_helped\",\n",
    "    \"How_long_was_the_trial\",\n",
    "    \"What_adverse_events_did_participants_report\",\n",
    "    \"What_happened_during_the_trial\",\n",
    "    \"What_treatments_did_the_participants_take\",\n",
    "    \"What_were_the_results_of_the_trial\",\n",
    "    \"Who_was_in_this_clinical_trial\",\n",
    "    \"Why_was_the_research_needed\"\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    print(f'Current file accessed: {file}')\n",
    "\n",
    "    input_file = 'FinalDataset/FullDataset2/'+ file +'.json'\n",
    "    output_file = 'FinalDataset/Results/'+ file +'_with_llm_answers.json'\n",
    "    # create_llm_answers(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99bc19c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
